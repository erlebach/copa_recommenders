{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages and Set Options\n",
    "Use Matrix Factorization with attributes to suggest destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Base Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import function_lib as flib\n",
    "\n",
    "import numpy as np\n",
    "#import numba as nb\n",
    "import pandas as pd\n",
    "# from scipy.sparse import csr_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import rankfmlib as rfmlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rankfm.rankfm import RankFM\n",
    "from rankfm.evaluation import hit_rate, reciprocal_rank, discounted_cumulative_gain, precision, recall, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "# plt.rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put the Main Package Library on the PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git_repo = git.Repo('.', search_parent_directories=True)\n",
    "# git_root = git_repo.git.rev_parse('--show-toplevel')\n",
    "# cython_path = os.path.join(git_root, 'rankfm')\n",
    "\n",
    "# sys.path[0] = git_root\n",
    "# sys.path[1] = cython_path\n",
    "# sys.path[:2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Compile Cython Extension Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd $git_root && python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamically Re-Load all Package Modules on Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set File Path Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/erlebach/src/2022/copa_recommenders/copa_recommender_data_rankfm/one_destination_per_member\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \".\" # os.path.join(git_root, \"data/instacart_2017_05_01\")\n",
    "# print(\"\\n\".join([git_root, data_path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Copa Data\n",
    "* Data for one year is included in each file.\n",
    "* Each file has three columns: userID (memberID), itemID (destination), rating (always 1)\n",
    "* The data was produced elsewhere (perhaps on my mac, perhaps not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Departments Data\n",
    "We will use 2016 for training and 2017 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member = {}\n",
    "df_attrib = {}\n",
    "year_train = 2016\n",
    "year_valid = 2017\n",
    "df_member_train, df_attrib_train = rfmlib.read_data_attributes(year_train)\n",
    "df_member_valid, df_attrib_valid = rfmlib.read_data_attributes(year_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, analyze 2016, training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 121803 121804 121805]\n"
     ]
    }
   ],
   "source": [
    "# I should probably randomize\n",
    "shuffle_index = np.arange(len(interactions))\n",
    "print(shuffle_index)\n",
    "np.random.shuffle(shuffle_index)\n",
    "interactions = df_member_train.copy().iloc[shuffle_index].reset_index(drop=True)     \n",
    "attributes = df_attrib_train.copy().iloc[shuffle_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sparsity': 0.9648460524660084, 'n_users': 23841, 'n_items': 76}\n"
     ]
    }
   ],
   "source": [
    "dct = rfmlib.sparsity(interactions)\n",
    "print(dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Random Subsample of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = interactions.user_id.unique()\n",
    "all_users1 = attributes.user_id.unique()\n",
    "assert(len(all_users) == len(all_users1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1492)\n",
    "nb_users = len(all_users)\n",
    "keep_nb_users = 10000\n",
    "# keep_nb_users = nb_users   # Keep all the users\n",
    "# shuffle the users\n",
    "s_users = np.random.choice(all_users, size=keep_nb_users, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the trips of the users selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51146, 2), (121806, 2))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_interactions = interactions[interactions.user_id.isin(s_users)].copy()\n",
    "s_attributes = attributes[interactions.user_id.isin(s_users)].copy()\n",
    "s_interactions.shape, interactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference is zero indicating equality. I ensured that users were ordered the same way in both dataframes\n",
    "(s_attributes.user_id.values - s_interactions.user_id.values).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of destinations travelled by the users kept in our selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb unique destinations:  76\n"
     ]
    }
   ],
   "source": [
    "s_items = s_interactions.product_id.unique()\n",
    "print(\"nb unique destinations: \", len(s_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RamkFM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-5d6b76686fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRamkFM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'RamkFM' is not defined"
     ]
    }
   ],
   "source": [
    "RamkFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum number of destinations for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_interactions.groupby(['user_id', 'product_id']).size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_trips</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230003257</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230161925</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230340635</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231120328</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231204984</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231429942</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231449144</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231981026</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nb_trips\n",
       "user_id            \n",
       "230003257        43\n",
       "230161925        41\n",
       "230340635        42\n",
       "231120328        43\n",
       "231204984        43\n",
       "231429942        42\n",
       "231449144        46\n",
       "231981026        46"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb_trips = s_interactions.groupby(['user_id'])['product_id'].size().to_frame('nb_trips')\n",
    "df_nb_trips[df_nb_trips['nb_trips'] > 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users taking many trips during the year are of two types: either they go to 2-3 destinations or they go to many different destinations. What are the characteristics of these users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>231449144</td>\n",
       "      <td>EZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10057</th>\n",
       "      <td>231449144</td>\n",
       "      <td>COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>231449144</td>\n",
       "      <td>SFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13051</th>\n",
       "      <td>231449144</td>\n",
       "      <td>LIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22825</th>\n",
       "      <td>231449144</td>\n",
       "      <td>BOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id product_id\n",
       "8255   231449144        EZE\n",
       "10057  231449144        COR\n",
       "11880  231449144        SFO\n",
       "13051  231449144        LIM\n",
       "22825  231449144        BOG"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_interactions[s_interactions['user_id'] == 231449144].head()  # remove head() for more destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RankFM(factors=20, loss='warp', max_samples=50, alpha=0.01, learning_rate=0.1, learning_schedule='invscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 0 ns, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sample_weight_train = interactions_dct[\"sample_weight_train\"]\n",
    "# item_features = \n",
    "sample_weight_train = np.ones(s_interactions.shape[0])\n",
    "model.fit(s_interactions, sample_weight=sample_weight_train, epochs=30, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([232182733, 230058605, 232633312, ..., 235675858, 230008857,\n",
       "       230046388])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_users = s_users[0:]\n",
    "valid_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 686 µs, total: 104 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_recs = model.recommend(valid_users, n_items=4, filter_previous=False, cold_start='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232182733</th>\n",
       "      <td>GRU</td>\n",
       "      <td>EZE</td>\n",
       "      <td>SFO</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230058605</th>\n",
       "      <td>VVI</td>\n",
       "      <td>SDQ</td>\n",
       "      <td>GUA</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232633312</th>\n",
       "      <td>JFK</td>\n",
       "      <td>EZE</td>\n",
       "      <td>MGA</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231248896</th>\n",
       "      <td>LIM</td>\n",
       "      <td>GUA</td>\n",
       "      <td>MEX</td>\n",
       "      <td>SDQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231829196</th>\n",
       "      <td>SJO</td>\n",
       "      <td>GUA</td>\n",
       "      <td>MGA</td>\n",
       "      <td>MAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230052725</th>\n",
       "      <td>GUA</td>\n",
       "      <td>SJO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>TPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231297767</th>\n",
       "      <td>SJO</td>\n",
       "      <td>POS</td>\n",
       "      <td>SDQ</td>\n",
       "      <td>BZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235675858</th>\n",
       "      <td>GRU</td>\n",
       "      <td>MEX</td>\n",
       "      <td>BOG</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230008857</th>\n",
       "      <td>PTY</td>\n",
       "      <td>MCO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>SDQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230046388</th>\n",
       "      <td>MDE</td>\n",
       "      <td>BOG</td>\n",
       "      <td>LIM</td>\n",
       "      <td>SJO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3\n",
       "232182733  GRU  EZE  SFO  MIA\n",
       "230058605  VVI  SDQ  GUA  MIA\n",
       "232633312  JFK  EZE  MGA  MIA\n",
       "231248896  LIM  GUA  MEX  SDQ\n",
       "231829196  SJO  GUA  MGA  MAR\n",
       "...        ...  ...  ...  ...\n",
       "230052725  GUA  SJO  LAS  TPA\n",
       "231297767  SJO  POS  SDQ  BZE\n",
       "235675858  GRU  MEX  BOG  MIA\n",
       "230008857  PTY  MCO  LAS  SDQ\n",
       "230046388  MDE  BOG  LIM  SJO\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NEW CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a User/Item Interaction Data Set with all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = {}\n",
    "for year in years:\n",
    "    df_g[year] = df[year].groupby(['user_id', 'product_id'])\n",
    "\n",
    "interactions = pd.concat([df[year] for year in years], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### Check that there is only one entry per member_id/destination/year group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interactions.groupby(['user_id','product_id','year']).size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders_cols = ['order_id', 'user_id']\n",
    "# order_products_cols = ['order_id', 'product_id']\n",
    "# interaction_cols = ['user_id', 'product_id', 'order_id']\n",
    "\n",
    "# interactions = pd.merge(orders_df[orders_cols], order_products_df[order_products_cols], on='order_id', how='inner')\n",
    "# interactions = interactions[interaction_cols]\n",
    "\n",
    "# interactions.info()\n",
    "# interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate User/Item Interaction Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2016].shape, df[2017].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = ranklib.sparsity(interactions)\n",
    "print(\"full interaction data sparsity: {}\".format(round(100 * dct['sparsity'], 2)))\n",
    "print(f\"n_users: {dct['n_users']}, n_items: {dct['n_items']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample the Data for Initial Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a Random Subsample of Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1492)\n",
    "nb_users = len(all_users)\n",
    "# keep_nb_users = 10000\n",
    "keep_nb_users = nb_users   # Keep all the users\n",
    "# shuffle the users\n",
    "s_users = np.random.choice(all_users, size=keep_nb_users, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_users), len(set(s_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Interactions for Those Users\n",
    "Only keep the users present in both years (NOT IMPLEMENTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_interactions = interactions[interactions.user_id.isin(s_users)].copy()\n",
    "s_interactions.shape, interactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_interacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of destinations travelled by users kept\n",
    "s_items = s_interactions.product_id.unique()\n",
    "len(s_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(interactions.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.groupby(['user_id', 'product_id']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected the maximum number of times a given member flew to a particular destination to be 1. \n",
    "Is it the case that when a member travels to a destination twice, it is in different years? Yes it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of times a given member flew to a particular destination is 2\n",
    "interactions.groupby(['user_id', 'product_id', 'year']).size().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-Evaluate Cardinality/Sparsity on the Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s_users = len(s_users)\n",
    "n_s_items = len(s_items)\n",
    "\n",
    "print(\"sample users:\", n_s_users)\n",
    "print(\"sample items:\", n_s_items)\n",
    "print(\"sample interactions:\", s_interactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sparsity = 1 - (s_interactions[['user_id', 'product_id']].drop_duplicates().shape[0] / (n_s_users * n_s_items))\n",
    "print(\"sample interaction data sparsity: {}\".format(round(100 * s_sparsity, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Training/Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly Shuffle the Overall Interaction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def shuffle_interaction_data(s_interactions):\n",
    "    shuffle_index = np.arange(len(s_interactions))\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    s_interactions = s_interactions.copy().iloc[shuffle_index]\n",
    "    return s_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_interactions, shuffle_index = rfmlib.shuffle_interaction_data(s_interactions)\n",
    "interactions_dct = rfmlib.train_validation(shuffled_interactions, 2016, 2017, shuffle_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interactions_dct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0d196c514d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minteractions_dct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'interactions_dct' is not defined"
     ]
    }
   ],
   "source": [
    "interactions_dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmlib.print_stats(interactions_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Out Core Package Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Model with Chosen Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# max_samples=500 creates problem for 'warp', but not for 'bpr'. Or vce-versa. What is the difference? And Why?\n",
    "# max_samples: nb negative samples\n",
    "model = RankFM(factors=50, loss='warp', max_samples=50, alpha=0.01, learning_rate=0.1, learning_schedule='invscaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model on the Training Data and Profile Computational Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_weight_train = interactions_dct[\"sample_weight_train\"]\n",
    "model.fit(interactions_train, sample_weight=sample_weight_train, epochs=30, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = model.predict(interactions_valid, cold_start='nan') # 'nan' or 'drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.shape, scores[2], len(interactions_train), len(interactions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0:100], len(scores), len(interactions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate TopN Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = pd.Series(interactions_train.user_id.unique())\n",
    "valid_users = pd.Series(interactions_valid.user_id.unique())\n",
    "both_users = set(train_users) & set(valid_users)\n",
    "cold_start_users = set(valid_users) - set(train_users)\n",
    "\n",
    "len(train_users), len(valid_users), len(both_users), len(cold_start_users), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_recs = model.recommend(valid_users, n_items=10, filter_previous=False, cold_start='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_recs_filter_prev = model.recommend(valid_users, n_items=10, filter_previous=True, cold_start='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_recs.shape)\n",
    "valid_recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_recs_filter_prev.shape)\n",
    "valid_recs_filter_prev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance on the Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Number of Recommended Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "topN = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Pure-Popularity Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = interactions_train.groupby('product_id')['user_id'].count().sort_values(ascending=False)[:k]\n",
    "most_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Create dictionary: member => list of destinations \n",
    "# Works even when there are there are multiple entries for the same (user_id, product_id)\n",
    "# 1/3 sec\n",
    "test_user_items = interactions_valid.groupby('user_id')['product_id'].apply(set)   # .to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Only keep users in the training set\n",
    "# 5.29 ms\n",
    "test_user_items = test_user_items.loc[list(both_users)].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time  \n",
    "# Only keep users contained in the training set\n",
    "# Create dictionary: member => list of items\n",
    "# Take 54 sec\n",
    "#test_user_items = {key: val for key, val in test_user_items.items() if key in set(train_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time  \n",
    "# Only keep users contained in the training set\n",
    "# Create dictionary: member => list of items\n",
    "# Take 54 sec because of python loops\n",
    "# test_user_items1 = {key: val for key, val in test_user_items.items() if key in set(train_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "base_hrt = np.mean([int(len(set(most_popular.index) & set(val)) > 0)                       for key, val in test_user_items.items()])\n",
    "base_pre = np.mean([len(set(most_popular.index) & set(val)) / len(set(most_popular.index)) for key, val in test_user_items.items()])\n",
    "base_rec = np.mean([len(set(most_popular.index) & set(val)) / len(set(val))                for key, val in test_user_items.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of test users: {}\".format(len(test_user_items)))\n",
    "print(\"baseline hit rate: {:.3f}\".format(base_hrt))\n",
    "print(\"baseline precision: {:.3f}\".format(base_pre))\n",
    "print(\"baseline recall: {:.3f}\".format(base_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Model Performance Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_hrt = hit_rate(model, interactions_valid, k=k)\n",
    "model_rnk = reciprocal_rank(model, interactions_valid, k=k)\n",
    "model_pre = precision(model, interactions_valid, k=k)\n",
    "model_rec = recall(model, interactions_valid, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model hit rate: {}\".format(round(model_hrt, 3)))\n",
    "print(\"model reciprocal rank: {}\".format(round(model_rnk, 3)))\n",
    "print(\"model precision: {}\".format(round(model_pre, 3)))\n",
    "print(\"model recall: {}\".format(round(model_rec, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions_valid.groupby('user_id')['product_id'].apply(set)   # .to_dict()\n",
    "interactions_train_Dlist = interactions_train.groupby('user_id')['product_id'].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function_lib as flib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hrt = flib.hit_rate(model, interactions_valid, k=5, filter_previous=False, max_kept=1, train_interactions=interactions_train_Dlist)\n",
    "# same function as in rankfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# average number of users for which at least one recommendation is correct\n",
    "# 77% hit rate! (at least one hit correct)\n",
    "# 26.6% hit rate (at least two hits correct)\n",
    "# 5.6% (three hits correct)\n",
    "# \n",
    "model_hrt = flib.hit_rate(model, interactions_valid, k=k, filter_previous=False)  # same function as in rankfm\n",
    "print(\"model_hrt(filter_previous=False): \", model_hrt)\n",
    "model_hrt = flib.hit_rate(model, interactions_valid, k=k, filter_previous=True)  # same function as in rankfm\n",
    "print(\"model_hrt(filter_previous=True): \", model_hrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for filt in [True, False]:\n",
    "    model_rnk = reciprocal_rank(model, interactions_valid, k=k, filter_previous=filt)\n",
    "    model_pre = precision(model, interactions_valid, k=k, filter_previous=filt)\n",
    "    model_rec = recall(model, interactions_valid, k=k, filter_previous=filt)\n",
    "    print(f\"model reciprocal rank(filter_previous={str(filt)}): {model_rnk:.3f}\")\n",
    "    print(f\"model precision(filter_previous={str(filt)}): {model_pre:.3f}\")\n",
    "    print(f\"model recall(filter_previous={str(filt)}): {model_rec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmlib.topn_recommendations(model, interactions_dct, base_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Assess the Diversity of Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diversity = diversity(model, interactions_valid, k=k).rename({'item_id': 'product_id'}, axis=1)\n",
    "model_diversity = pd.merge(model_diversity, products_df, on='product_id', how='inner')\n",
    "model_diversity = model_diversity[['cnt_users', 'pct_users', 'product_id', 'product_name', 'aisle_id', 'department_id']]\n",
    "model_diversity.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = np.mean(model_diversity['cnt_users'] > 0)\n",
    "round(coverage, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero = model_diversity[model_diversity.cnt_users > 0]\n",
    "entropy = -np.sum(nonzero['pct_users'] * np.log2(nonzero['pct_users']))\n",
    "round(entropy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=[16, 4])\n",
    "N = 50\n",
    "\n",
    "topN = model_diversity.iloc[:N, :]\n",
    "axes.bar(topN.index.values + 1, topN.pct_users, width=1, edgecolor='black', alpha=0.75)\n",
    "axes.set(xlabel='Item Rank', ylabel='Percentage of Users', title='Percentage of Users Recommended by Item Rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Similar Items for a Few Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = np.random.choice(valid_users)\n",
    "print(\"random user: {}\".format(random_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user_recs = valid_recs.loc[random_user]\n",
    "random_user_recs = products_df[products_df.product_id.isin(random_user_recs)].set_index('product_id').loc[random_user_recs]\n",
    "random_user_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Similar Products for a Few of the Random User's Recommended Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_items = model.similar_items(48370)\n",
    "most_similar_items = products_df.set_index('product_id').loc[most_similar_items]\n",
    "most_similar_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asess Model Performance on Novel Item Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save an Array of the Most Popular Items in the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = interactions_train.groupby('product_id')['user_id'].count().sort_values(ascending=False)\n",
    "print(len(most_popular))\n",
    "most_popular.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular = pd.Series(most_popular.index.values)\n",
    "most_popular[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the TopK Most Popular Items Not Yet Previously Purchased for Each Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_items = interactions_train.groupby('user_id')['product_id'].apply(set).to_dict()\n",
    "train_user_items = {key: val for key, val in test_user_items.items() if key in set(valid_users)}\n",
    "most_popular_new = {user: most_popular[~most_popular.isin(train_user_items[user])][:k] for user in train_user_items.keys()}\n",
    "len(most_popular_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(most_popular_new.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_new[100232578]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Pure-Popularity Baseline Metrics on Previously Unpurchased Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_new_hrt = np.mean([int(len(set(most_popular_new[user]) & set(test_user_items[user])) > 0)                           for user in test_user_items.keys()])\n",
    "base_new_pre = np.mean([len(set(most_popular_new[user]) & set(test_user_items[user])) / len(set(most_popular_new[user])) for user in test_user_items.keys()])\n",
    "base_new_rec = np.mean([len(set(most_popular_new[user]) & set(test_user_items[user])) / len(set(test_user_items[user]))  for user in test_user_items.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of test users: {}\".format(len(test_user_items)))\n",
    "print(\"baseline new hit rate: {:.3f}\".format(base_new_hrt))\n",
    "print(\"baseline new precision: {:.3f}\".format(base_new_pre))\n",
    "print(\"baseline new recall: {:.3f}\".format(base_new_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Model Performance Excluding Training Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_hrt_new = hit_rate(model, interactions_valid, k=k, filter_previous=True)\n",
    "model_pre_new = precision(model, interactions_valid, k=k, filter_previous=True)\n",
    "model_rec_new = recall(model, interactions_valid, k=k, filter_previous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model new hit rate: {}\".format(round(model_hrt_new, 3)))\n",
    "print(\"model new precision: {}\".format(round(model_pre_new, 3)))\n",
    "print(\"model new recall: {}\".format(round(model_rec_new, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
