{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b5aa87-94a6-401d-bea8-affeb2eb4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd87573-0b2b-44e5-a7ac-e54740713292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dd8d300-b81c-4cc6-977c-5c697fbfc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise as sur\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import item_item as ii  # in ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ba897b-bd0d-4803-926a-9510a2bd8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import date_library as dlib  # in ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a5e675-200f-433d-98b8-603f43318590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_year(df, year):\n",
    "    first = year + '-01-01'\n",
    "    last = year + '-12-31'\n",
    "    return df[(df['date'] >= first) & (df['date'] <= last)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79877ebd-3115-471f-894d-41546d48a30d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert items and uses to integers ranging from [0,n] and [0,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50c6b893-857b-43c5-a5a2-362dc2f34858",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'member_d.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-13698753afb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"member_d.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'userID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'itemID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flight_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'family_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df['rating'] = df['rating'].clip(lower=0., upper=max_rating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'member_d.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"member_d.csv\")\n",
    "df.columns = ['userID', 'itemID', 'flight_date', 'family_size']\n",
    "max_rating = 5\n",
    "#df['rating'] = df['rating'].clip(lower=0., upper=max_rating)\n",
    "df['rating'] = 1\n",
    "reader = Reader(rating_scale=[1, max_rating])   # All ratings are 1\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ee3516-1680-41a9-b1aa-0aba228c842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates.min:  ('2015-02-04', '05:00')\n",
      "dates.max:  ('2022-12-30', '05:00')\n"
     ]
    }
   ],
   "source": [
    "dates = df.flight_date.values\n",
    "# Date routines work properly in both directions\n",
    "# it is not clear why the max date is Dec. 2022? That should not be!\n",
    "print(\"dates.min: \", dlib.timestampToDateTimePTY(dates.min()))\n",
    "print(\"dates.max: \", dlib.timestampToDateTimePTY(dates.max()))\n",
    "\n",
    "# dlib.timestampToDateTimePTY(date)\n",
    "new_dates = []\n",
    "for date in dates:\n",
    "    d = dlib.timestampToDateTimePTY(date)[0]\n",
    "    new_dates.append(d)\n",
    "\n",
    "# Choose dates in 2016\n",
    "df['date'] = new_dates\n",
    "df = df.sort_values('flight_date')\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80404f4e-79e5-46e5-8b1a-693fbcde3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2015, nb records: (31703, 6)\n",
      "year: 2016, nb records: (119873, 6)\n",
      "year: 2017, nb records: (145362, 6)\n",
      "year: 2018, nb records: (175231, 6)\n",
      "year: 2019, nb records: (204299, 6)\n",
      "year: 2020, nb records: (61658, 6)\n",
      "year: 2021, nb records: (88174, 6)\n",
      "year: 2022, nb records: (23191, 6)\n"
     ]
    }
   ],
   "source": [
    "df_years = {}\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "for year in years:\n",
    "    df_years[year] = dates_year(df, year)\n",
    "    print(f\"year: {year}, nb records: {df_years[year].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5ee781-62d3-4a0b-851e-edfa6ad6c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = {}\n",
    "for year in years:\n",
    "    dff[year] = df_years[year].groupby(['userID','itemID']).size().to_frame('rating').reset_index()\n",
    "    dff[year]['rating'] = 1 # Do not take nb of trips to a destination into account (YET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd164756-6212-448b-a8ee-d972d3adeeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "members_2015\n",
      "2015: 21605 rows\n",
      "members_2016\n",
      "2016: 62991 rows\n",
      "members_2017\n",
      "2017: 74658 rows\n",
      "members_2018\n",
      "2018: 88419 rows\n",
      "members_2019\n",
      "2019: 100967 rows\n",
      "members_2020\n",
      "2020: 45284 rows\n",
      "members_2021\n",
      "2021: 53372 rows\n",
      "members_2022\n",
      "2022: 19854 rows\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(\"members_\"+year)\n",
    "    print(f\"{year}: {dff[year].shape[0]} rows\")\n",
    "    dff[year].to_csv(f\"members_{year}.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db5295d0-314a-4d5c-9fd9-fb705211cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw ratings: 21605\n",
      "Raw ratings: 62991\n",
      "Raw ratings: 74658\n",
      "Raw ratings: 88419\n",
      "Raw ratings: 100967\n",
      "Raw ratings: 45284\n",
      "Raw ratings: 53372\n",
      "Raw ratings: 19854\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=[1, 1])\n",
    "\n",
    "data_training = {}\n",
    "\n",
    "for year in years:\n",
    "    data_training[year] = Dataset.load_from_df(dff[year][['userID', 'itemID', 'rating']], reader)\n",
    "    print(f\"Raw ratings: {data_training[year].df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52b7dd10-0ad2-4c6e-a342-79062ff86168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015: 11313, 74\n",
      "2016: 23562, 76\n",
      "2017: 28011, 75\n",
      "2018: 32883, 80\n",
      "2019: 37718, 81\n",
      "2020: 30444, 80\n",
      "2021: 31138, 74\n",
      "2022: 15621, 75\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for year in years:\n",
    "    d[year] = data_training[year].build_full_trainset()\n",
    "    print(f\"{year}: {len(d[year].ur.keys())}, {len(d[year].ir.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd976f12-9fc7-4f1e-9102-214044b873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb users:  28011\n"
     ]
    }
   ],
   "source": [
    "# Do all members have a destination? I do not think so\n",
    "g = dff['2017'].groupby('userID')\n",
    "g.groups.items()\n",
    "for k, items in  g.groups.items():\n",
    "    nb_items = len(items)\n",
    "    if nb_items == 0:\n",
    "        print(\"no items\")\n",
    "print(\"nb users: \", len(g.groups.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9360c23b-aa5c-406c-b134-6ef43c791b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2015, 21605\n",
      "Year: 2016, 62991\n",
      "Year: 2017, 74658\n",
      "Year: 2018, 88419\n",
      "Year: 2019, 100967\n",
      "Year: 2020, 45284\n",
      "Year: 2021, 53372\n",
      "Year: 2022, 19854\n"
     ]
    }
   ],
   "source": [
    "# matches the total number of destinations computed below\n",
    "for year in years:\n",
    "    all_ratings = d[year].all_ratings()\n",
    "    print(f\"Year: {year}, {len(list(all_ratings))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70f18a6b-d33f-4e49-aa49-8037953cd104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the number of items with no destinations. Should be zero.\n",
    "if False:\n",
    "    for year in years:\n",
    "        print(\"==> \", year)\n",
    "        ii.count_zero_items(d[year], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb777f58-91e6-4c06-8314-a5faf48a68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size to store user-item data in full arrays: \n",
    "total = 0\n",
    "for year in years:\n",
    "    sz = d[year].n_users * d[year].n_items\n",
    "    total += sz\n",
    "    # print(\"year: \",  year, \", \", d[year].n_users * d[year].n_items)\n",
    "# print(\"total: \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c0703-21f5-4fc4-a187-8ffacd5eaa60",
   "metadata": {},
   "source": [
    "### Construct user-item matrix, with each row normalized to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c03f736-3245-4892-a1f0-0cedfd63ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 3.82 ms, total: 244 ms\n",
      "Wall time: 243 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in years:\n",
    "    ii.user_item_row_norms(d[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de507b39-bce2-4768-b55f-ee910f746637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 608 µs, sys: 0 ns, total: 608 µs\n",
      "Wall time: 609 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in years:\n",
    "    ii.user_item_col_norms(d[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf9a091-35de-4a67-95e2-1c86049a2165",
   "metadata": {},
   "source": [
    "# Construct user-item matrix as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c854482f-fb24-4039-b95c-10da788226e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 0 ns, total: 245 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r_norms = {}; r_norms_inv_sq = {}\n",
    "c_norms = {}; c_norms_inv = {}\n",
    "for year in years:\n",
    "    r_norms[year], r_norms_inv_sq[year] = ii.user_item_row_norms(d[year])\n",
    "    c_norms[year], c_norms_inv[year] = ii.user_item_col_norms(d[year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0dde98a-d4c8-47cd-8d9c-bb1cc7308a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "CPU times: user 12.6 s, sys: 199 ms, total: 12.8 s\n",
      "Wall time: 898 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "simil_matrix = {}\n",
    "user_item = {}\n",
    "user_item_row_normalized = {}\n",
    "simil_matrix_row_normalized = {}\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    user_item[year] = ii.user_item_matrix(d[year])\n",
    "    simil_matrix[year] = ii.sim_matrix(user_item[year])\n",
    "    \n",
    "    user_item_row_normalized[year] = ii.user_item_matrix_row_normalized(user_item[year], r_norms[year])\n",
    "    simil_matrix_row_normalized[year] = ii.sim_matrix(user_item_row_normalized[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c4950a-3cf1-4a88-bc9a-e949261b5e75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select recommendations\n",
    "The plan is to select users at random and provide N top recommendations.  This will require translating items recommended back to destinations.  I will have to figure out how to evaluate the quality of the recommendations.  I will probably use the Hit Rate (HR) metric since it works and is simple to implement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc876e4a-e3bd-4eb4-9978-6a2ad70fb2b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Destinations traveled the following year\n",
    "* Store destinations travelled by members in 2017\n",
    "* Compare these destinations with the predictions made on the basis of 2016\n",
    "\n",
    "* Future plans: Add attributes to the trips: \n",
    "    * country of origin\n",
    "    * gender\n",
    "    * family size\n",
    "    * cost of trip\n",
    "    * month flown\n",
    "    * trip duration\n",
    "    * type of trip (can probably be determined from family size and frequency)\n",
    "    \n",
    "* Note: should we take into account travel of members going to many places per month? Is it likely that the recommender will have an effect? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee1b56b5-aae1-4989-8983-5bd84aa3ad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(range(0, 23562), range(0, 28011))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data from 2017 (one year past the training data): stored in dtest (created by Surprise)\n",
    "d['2016'].all_users(), d['2017'].all_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af03a56-dca5-4292-9eeb-4a5bb0196f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = {}\n",
    "for year in years:\n",
    "    members[year] = ii.get_raw_users(d, year)\n",
    "    # print(f\"Year: {year}, nb members: {len(members[year])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98d2032a-c2bd-4e26-93b6-368683f702bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20535"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersect these two sets to find the members in 2017 that flew in 2016, and for which I have preditions\n",
    "users_common = members['2016'].intersection(members['2017'])\n",
    "len(users_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18b1a0ed-0ace-4d61-bba1-16347b34154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2018 based on 2017: 7174/24653: 0.2909990670506632\n"
     ]
    }
   ],
   "source": [
    "ii.predictions(members, d,  simil_matrix, train_year='2017', test_year='2018', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f796602e-0c8e-426a-bcf9-bf11a8ec12a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015', '2016', '2017', '2018', '2019']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years4 = years[0:5]\n",
    "years4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f029eef6-5379-4732-b509-87d72c3764bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2016 based on 2015: 3503/10152: 0.34505516154452326\n",
      "Percentage with a correct prediction 2017 based on 2015: 3451/9938: 0.34725296840410547\n",
      "Percentage with a correct prediction 2018 based on 2015: 3527/9971: 0.35372580483401866\n",
      "Percentage with a correct prediction 2019 based on 2015: 3488/9938: 0.3509760515194204\n",
      "Percentage with a correct prediction 2017 based on 2016: 6117/20535: 0.297881665449233\n",
      "Percentage with a correct prediction 2018 based on 2016: 6722/20705: 0.32465588022216857\n",
      "Percentage with a correct prediction 2019 based on 2016: 6913/20674: 0.334381348553739\n",
      "Percentage with a correct prediction 2018 based on 2017: 7174/24653: 0.2909990670506632\n",
      "Percentage with a correct prediction 2019 based on 2017: 7555/24640: 0.3066152597402597\n",
      "Percentage with a correct prediction 2019 based on 2018: 8299/29044: 0.28573887894229444\n"
     ]
    }
   ],
   "source": [
    "for i1 in range(0, len(years4)):\n",
    "    for i2 in range(i1+1, len(years4)):\n",
    "        ii.predictions(members, d, simil_matrix, train_year=years4[i1], test_year=years4[i2], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cbb00d8-a08c-4b54-bb08-89bb98fd8378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2015 based on 2016: 1967/10152: 0.19375492513790385\n",
      "Percentage with a correct prediction 2015 based on 2017: 1982/9938: 0.19943650633930368\n",
      "Percentage with a correct prediction 2015 based on 2018: 2040/9971: 0.2045933206298265\n",
      "Percentage with a correct prediction 2015 based on 2019: 2098/9938: 0.21110887502515596\n",
      "Percentage with a correct prediction 2016 based on 2017: 5587/20535: 0.27207207207207207\n",
      "Percentage with a correct prediction 2016 based on 2018: 5916/20705: 0.2857280850036223\n",
      "Percentage with a correct prediction 2016 based on 2019: 6021/20674: 0.291235368095192\n",
      "Percentage with a correct prediction 2017 based on 2018: 6577/24653: 0.266782947308644\n",
      "Percentage with a correct prediction 2017 based on 2019: 6950/24640: 0.2820616883116883\n",
      "Percentage with a correct prediction 2018 based on 2019: 7693/29044: 0.26487398429968323\n"
     ]
    }
   ],
   "source": [
    "# Predict past from the future\n",
    "# Will the results be the similar?\n",
    "for i1 in range(0, len(years4)):\n",
    "    for i2 in range(i1+1, len(years4)):\n",
    "        ii.predictions(members, d, simil_matrix, train_year=years4[i2], test_year=years4[i1], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f14acfe1-65f4-4ca8-99ba-ff37fa325bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2016 based on 2015: 3507/10152: 0.34544917257683216\n",
      "Percentage with a correct prediction 2017 based on 2015: 3431/9938: 0.34524049104447574\n",
      "Percentage with a correct prediction 2018 based on 2015: 3516/9971: 0.35262260555611274\n",
      "Percentage with a correct prediction 2019 based on 2015: 3484/9938: 0.35057355604749446\n",
      "Percentage with a correct prediction 2017 based on 2016: 6208/20535: 0.3023131239347456\n",
      "Percentage with a correct prediction 2018 based on 2016: 6850/20705: 0.330837961844965\n",
      "Percentage with a correct prediction 2019 based on 2016: 7017/20674: 0.33941182161168615\n",
      "Percentage with a correct prediction 2018 based on 2017: 7258/24653: 0.29440636028069606\n",
      "Percentage with a correct prediction 2019 based on 2017: 7696/24640: 0.31233766233766236\n",
      "Percentage with a correct prediction 2019 based on 2018: 8355/29044: 0.2876669880181793\n"
     ]
    }
   ],
   "source": [
    "# Row normalization worsened the results on the first four results, but slightly improved\n",
    "# the remainder. It improved things when there is one year difference. Made things worse if there \n",
    "# is more than one year difference. \n",
    "for i1 in range(0, len(years4)):\n",
    "    for i2 in range(i1+1, len(years4)):\n",
    "        ii.predictions(members, d, simil_matrix_row_normalized, train_year=years4[i1], test_year=years4[i2], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222c1d6-b899-4dd8-8f3b-a49de458c1eb",
   "metadata": {},
   "source": [
    "## Normalize rows of Model matrix before computing similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adade9c-ce12-426e-81ba-2cd506c6fe94",
   "metadata": {},
   "source": [
    "## Use asymmetric similarities based on probability modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe6f36-5d30-4a35-a696-2bfa5f760188",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "095cade4-dfb1-493e-8dbb-5855239e38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(data):\n",
    "    n_items = data.n_items\n",
    "    dct = defaultdict(set)\n",
    "\n",
    "    for i in range(n_items):\n",
    "        users = data.ir[i]\n",
    "        for user, _ in users:\n",
    "            dct[i].add(user)\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e2e68bd-8060-48a6-91a7-0be36954f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(data, dct):\n",
    "    n_items = data.n_items\n",
    "    sim1 = np.zeros([n_items, n_items])\n",
    "    sim2 = np.zeros([n_items, n_items])\n",
    "    for item1 in range(n_items):\n",
    "        for item2 in range(n_items):\n",
    "            nbij = len(dct[item1].intersection(dct[item2]))\n",
    "            if nbij > 0:\n",
    "                sim1[item1, item2] = nbij / len(dct[item2])\n",
    "                sim2[item1, item2] = nbij / (len(dct[item1]) * len(dct[item2]))\n",
    "    return sim1,  sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a493f9-cc1d-4dab-8e6d-1641e91d8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2a = {}\n",
    "sim2b = {}\n",
    "for year in years:\n",
    "    dct = calc(d[year])\n",
    "    sim2a[year], sim2b[year] = prob(d[year], dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c398e98-98ca-4b0d-86c3-4d07aff595bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of sim2a['2017'] / sim2b['2017'] are constant. \n",
    "# AS A RESULT, the prediction algorithm produces the same results\n",
    "# for both matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6092617-0619-48d2-bd18-607e687cb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2016 based on 2015: 3652/10152: 0.35973207249802996\n",
      "Percentage with a correct prediction 2017 based on 2015: 3652/9938: 0.367478365868384\n",
      "Percentage with a correct prediction 2018 based on 2015: 3780/9971: 0.379099388225855\n",
      "Percentage with a correct prediction 2019 based on 2015: 3821/9938: 0.384483799557255\n",
      "Percentage with a correct prediction 2017 based on 2016: 6108/20535: 0.29744338933528125\n",
      "Percentage with a correct prediction 2018 based on 2016: 6774/20705: 0.3271673508814296\n",
      "Percentage with a correct prediction 2019 based on 2016: 7102/20674: 0.343523265937893\n",
      "Percentage with a correct prediction 2018 based on 2017: 7145/24653: 0.289822739626009\n",
      "Percentage with a correct prediction 2019 based on 2017: 7657/24640: 0.31075487012987013\n",
      "Percentage with a correct prediction 2019 based on 2018: 8290/29044: 0.2854290042693844\n"
     ]
    }
   ],
   "source": [
    "# The results are slightly better than the symmetric version!\n",
    "for i1 in range(0, len(years4)):\n",
    "    for i2 in range(i1+1, len(years4)):\n",
    "        ii.predictions(members, d, sim2a, train_year=years4[i1], test_year=years4[i2], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ed81e71-8fd8-4b82-a45d-86ed569f8691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage with a correct prediction 2016 based on 2015: 888/10152: 0.08747044917257683\n",
      "Percentage with a correct prediction 2017 based on 2015: 854/9938: 0.08593278325618837\n",
      "Percentage with a correct prediction 2018 based on 2015: 812/9971: 0.08143616487814663\n",
      "Percentage with a correct prediction 2019 based on 2015: 785/9938: 0.07898973636546588\n",
      "Percentage with a correct prediction 2017 based on 2016: 1713/20535: 0.08341855368882396\n",
      "Percentage with a correct prediction 2018 based on 2016: 1786/20705: 0.08625935764308137\n",
      "Percentage with a correct prediction 2019 based on 2016: 1840/20674: 0.0890006771790655\n",
      "Percentage with a correct prediction 2018 based on 2017: 2354/24653: 0.09548533647020646\n",
      "Percentage with a correct prediction 2019 based on 2017: 2375/24640: 0.09638798701298701\n",
      "Percentage with a correct prediction 2019 based on 2018: 2318/29044: 0.07980994353394849\n"
     ]
    }
   ],
   "source": [
    "# Very poor results\n",
    "for i1 in range(0, len(years4)):\n",
    "    for i2 in range(i1+1, len(years4)):\n",
    "        ii.predictions(members, d, sim2b, train_year=years4[i1], test_year=years4[i2], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4e4b3b66-94e6-4c2b-a925-c4994b37158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the version with the power of alpha in denominator. It is hard to believe that I will do better. \n",
    "# TRY IT OUT. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4784de9-c366-4b41-9757-d74a96d5fd69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed8b64-19cc-47d8-9990-cc136ee798c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "520bda95-daac-40f6-a8e9-8548f7d96805",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ead8e7-f6c7-4e00-8271-6a8181237eb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efbfe1-f5cc-4f0e-805a-b9bebb1d5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"member_d.csv\")\n",
    "df.columns = ['userID', 'itemID', 'flight_date', 'rating']\n",
    "max_rating = 5\n",
    "df['rating'] = df['rating'].clip(lower=0., upper=max_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc1e0c-3e6c-45af-8d97-4e63942187c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Number of trips to each destination of full time period (2015-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d6aaf-802c-4e72-b9fd-9d4cdc255121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('itemID')\n",
    "dfg.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426b629-5e64-4f0d-9642-4af9dd99cddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Number of trips taken to pairs of destinations\n",
    "* How to compute this efficiently? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1d27b-845f-4ad1-8f72-3895991555e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('userID')\n",
    "dfgg = dfg.groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91ea53-7f43-4f31-831c-dfeee49d94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8f08d-adee-4d81-b2cb-cc782ffa4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437fc6d-bc45-467f-8199-9b38acb7fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all destinations\n",
    "destinations = set()\n",
    "for d in df['itemID'].values:\n",
    "    destinations.add(d)\n",
    "destinations = list(destinations)\n",
    "print(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218224b8-2740-460e-91b3-8838ef4e9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('userID')\n",
    "dfgg = dfg.groups\n",
    "# dfgg.get_group[user] is a list of users\n",
    "\n",
    "users = defaultdict(int)\n",
    "for ix, k in enumerate(dfgg.keys()):\n",
    "    g = dfg.get_group(k)\n",
    "    users[k] = defaultdict(int)\n",
    "    for d in g.itemID:\n",
    "        users[k][d] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0b46c-5110-4800-8660-0175bd41e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = df.groupby('itemID')\n",
    "dfdd = dfd.groups\n",
    "    \n",
    "items = defaultdict(int)\n",
    "for ix, k in enumerate(dfdd.keys()):\n",
    "    g = df.iloc[dfdd[k]]\n",
    "    items[k] = defaultdict(int)\n",
    "    for d in g.userID:\n",
    "        items[k][d] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae17145-e853-4c75-85bf-f5eba1336135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute column-norms of similarity matrix (symmetric)\n",
    "sim = defaultdict(float)   # sim[item1, item2]\n",
    "norm = defaultdict(float)\n",
    "for k, v in items.items():\n",
    "    norm[k] = np.sqrt(len(v))  # L2-norm of columns of user-item matrix R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e29374-1b7f-465f-a921-100329768a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute row-norms of user-item matrix R\n",
    "# Objective: increase weighting of users going to fewer destinations\n",
    "# A user going to all destinations should not contribute to the recommendations\n",
    "row_norm = defaultdict(float)\n",
    "for k, v in users.items():\n",
    "    row_norm[k] = np.sqrt(len(v))  # L2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dfb3db-3615-4787-8f2b-177862ea155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0edec6-eba8-442c-b0e5-3f1e2ce8ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For each item, store the users that purchased it\n",
    "# NOT USED\n",
    "dfd = df.groupby('itemID')\n",
    "dfdd = dfd.groups\n",
    "    \n",
    "# make rows of R unit length\n",
    "items_norm = defaultdict(int)\n",
    "for ix, k in enumerate(dfdd.keys()):  # dfdd[k]: list of users\n",
    "    g = dfd.get_group(k)  # takes longer, easier to read\n",
    "    items_norm[k] = defaultdict(int)\n",
    "    for d in g.userID:\n",
    "        items_norm[k][d] = 1 / row_norm[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b37a4-7c6a-451a-b17a-faa6e2226f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "items.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed1953-a399-42e0-ba0a-95312ffe689c",
   "metadata": {},
   "source": [
    "* Next cell takes a long time (50k users and 80 destinations). I am working with dictionaries, which might explain the slowness. \n",
    "* However, there is strong sparsity, so the slowness is overdone. \n",
    "* Another reason might be be because "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bc442-d98b-40d7-be27-a2bec6ca1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae9004-239d-42cc-89d4-dac4c815f349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4534ffd-07b4-4449-a4fc-36dffa8d179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations1 = destinations[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c5996-48a8-491a-803b-98ff41f5a8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e958536-1444-4e41-9c66-e0b6da68101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Symmetric version\n",
    "\n",
    "try:\n",
    "    del sim\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sim = defaultdict(float)\n",
    "items = destinations1\n",
    "\n",
    "for d1 in items:\n",
    "    print(\"d1: \", d1)\n",
    "    for d2 in items:\n",
    "        for k, v in users.items():\n",
    "            sim[(d1,d2)] += v[d1] * v[d2]\n",
    "        sim[(d1,d2)] /= (norm[d1] * norm[d2])\n",
    "        \n",
    "for d1 in items:\n",
    "    sim[(d1,d1)] = 0.   # Remove diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa201a-ff9f-44a9-b3a2-66caa78ebd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Symmetric version (with row-normalization)\n",
    "\n",
    "try:\n",
    "    del sim_row_norm\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sim_row_norm = defaultdict(float)\n",
    "items = destinations1\n",
    "\n",
    "for d1 in items:\n",
    "    print(\"d1: \", d1)\n",
    "    for d2 in items:\n",
    "        for k, v in users.items():            # xx = v[d1] * v[d2] / row_norm[v]**2\n",
    "            # Division on the next line doubles execution time\n",
    "            sim_row_norm[(d1,d2)] += (v[d1] * v[d2] / row_norm[k]**2)\n",
    "        sim_row_norm[(d1,d2)] /= (norm[d1] * norm[d2])\n",
    "        \n",
    "for d1 in items:\n",
    "    sim_row_norm[(d1,d1)] = 0.   # Remove diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdfc8d-2d7c-40a2-b88d-6d10efda8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sim.items())\n",
    "l.sort(key=lambda x: -x[1])\n",
    "l[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eac23b-964d-4395-bd4e-b217665d5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sim_row_norm.items())\n",
    "l.sort(key=lambda x: -x[1])\n",
    "l[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750b033-bc8e-49ed-8598-3b7040c20eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in items:\n",
    "    print(i, sim[('GEO',i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37fe49-451e-45da-b54f-53490f082d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in items:\n",
    "    print(i, sim_row_norm[('GEO',i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ef336-b337-4d2c-935c-6d599d7f7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sim[('POA','GUA')])\n",
    "display(sim[('GUA','POA')])\n",
    "display(sim_row_norm[('POA','GUA')])\n",
    "display(sim_row_norm[('GUA','POA')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acf510-9c54-4c65-baf4-b24f63730572",
   "metadata": {},
   "source": [
    "## Initial Test (see Surprise Documentation and example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d7793-02ff-4de6-9e46-18145fd1f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"member_d.csv\")\n",
    "df.columns = ['userID', 'itemID', 'flight_date', 'rating']\n",
    "max_rating = 5\n",
    "df['rating'] = df['rating'].clip(lower=0., upper=max_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1878e-bf80-4c09-9d37-3421d04a55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=[1, 5])\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69f0df-6309-449e-8d6d-33a02f7b32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f957d-aa4f-417e-bc39-e579b249135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the famous SVD algorithm.\n",
    "algo = sur.SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98d5be-a819-4841-a7ff-5fd3acb74901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dffc32-cc39-44e3-a5aa-63298dd6cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31107e7b-9724-4768-92cc-2e5c4e611071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Then compute RMSE\n",
    "sur.accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30e10-6cf7-4b89-ab9d-616732b77060",
   "metadata": {},
   "source": [
    "## Sort the dataframe by increasing flight_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84ca64-9b75-49f2-aab2-6cf6140846e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('flight_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba951017-8022-4c94-ac5b-868842e2bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c236a8-769b-4da6-b320-d2cf81cae783",
   "metadata": {},
   "source": [
    "### Convert to regular dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb18a7-71b1-4307-8c47-24f0410570fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import date_library as dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e502cd-a22d-4bd1-903f-ae72f2a9b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2022-03-01'\n",
    "d1 = dlib.dateTimePTYToTimestamp(date)\n",
    "d2 = dlib.timestampToDateTimePTY(d1)\n",
    "print(\"d1: \", d1)\n",
    "print(\"d2: \", d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803611d-2090-46b1-86ee-d657e2d92b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates = df.flight_date.values\n",
    "print(dates)\n",
    "print(dates.min())\n",
    "# Date routines work properly in both directions\n",
    "# it is not clear why the max date is Dec. 2022? That should not be!\n",
    "print(\"dates.min: \", dlib.timestampToDateTimePTY(dates.min()))\n",
    "print(\"dates.max: \", dlib.timestampToDateTimePTY(dates.max()))\n",
    "\n",
    "# dlib.timestampToDateTimePTY(date)\n",
    "new_dates = []\n",
    "for date in dates:\n",
    "    d = dlib.timestampToDateTimePTY(date)[0]\n",
    "    new_dates.append(d)\n",
    "    \n",
    "#new_dates.sort()\n",
    "# new_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83346600-01c9-4bb9-8c20-5fc901fe42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dates in 2016\n",
    "df['date'] = new_dates\n",
    "len(new_dates)\n",
    "df = df.sort_values('flight_date')\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818b633f-2ac4-45a7-80d6-423fb2ea0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_2016 = df[(df['date'] > '2015-12-31') & (df['date'] < '2017-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2eaf1-b19f-4695-8614-ae318d1c5034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfe059-0ccd-4bfd-a5ec-0cdb3e1ee98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1405a-a3e0-4c68-a683-824f55a8d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=[1, 5])\n",
    "\n",
    "df_train = df_years['2016']\n",
    "df_test = df_years['2017']\n",
    "data_training = Dataset.load_from_df(df_train[['userID', 'itemID', 'rating']], reader)\n",
    "data_testing = Dataset.load_from_df(df_test[['userID', 'itemID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff848f-dae1-465d-a596-acbaaaac0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, x = train_test_split(data_training, test_size=.1)\n",
    "y, testset = train_test_split(data_testing, test_size=.9)\n",
    "# testset is a list (each element is 3 elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f273d4d-bbb7-42cc-ba93-468479b0b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = sur.SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91df1a-1363-4df3-a656-60a503935b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove from test set all (user, item) combinations already contained in the training set\n",
    "# List of (user, dest) in the training set\n",
    "user_d_train = set()\n",
    "uid = trainset.to_raw_uid\n",
    "iid = trainset.to_raw_iid\n",
    "for el in trainset.all_ratings():\n",
    "    # print(u,i,r)\n",
    "    # print(el)\n",
    "    # print(uid(el[0]), iid(el[1]),  el[2])\n",
    "    user_d_train.add((uid(el[0]), iid(el[1]), el[2]))\n",
    "user_d_list = list(user_d_train)\n",
    "print(len(user_d_train)), print(user_d_list[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7e0bb-66b5-437f-a158-71d1e03f5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = set()\n",
    "trained_test = set()\n",
    "for el in testset:\n",
    "    if el not in user_d_train:\n",
    "        new_test.add(el)\n",
    "    else:\n",
    "        trained_test.add(el)\n",
    "print(\"new test set: \", len(new_test))\n",
    "print(\"trained test set: \", len(trained_test))\n",
    "print(\"full test set: \", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2e953-5bf6-4036-80c6-0c26305a6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a list of predictions for 100 user ids with all destinations\n",
    "# Remove all those already in the test set. The remainder will not have \n",
    "# the city chosen. I wonder what the predictions are. \n",
    "# Question: I am not sure whether the recommender should predict zero for the trips not taken. \n",
    "#    After all, who knows whether the member would have taken the trip if given the opportunity? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e166c9a-1a9c-4a02-b662-9b68b4e4c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect destinations from training set\n",
    "destinations = set()\n",
    "for rating in trainset.all_items():\n",
    "    destinations.add(trainset.to_raw_iid(rating))\n",
    "destinations = list(destinations)\n",
    "print(len(destinations), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645593d1-fe08-4e73-9d1c-ac47aef3991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ab2d5-6000-4790-88f1-d6331a389fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = set()\n",
    "test_not_visited = []\n",
    "for i in range(10):\n",
    "    users.add(predictions[i].uid)\n",
    "users = list(users)\n",
    "for user in users:\n",
    "    for d in destinations:\n",
    "        pred = (user, d, 0.)\n",
    "        test_not_visited.append(pred)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1e1a4-7d0c-45b7-8090-5026947e414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "predictions = algo.test(new_test)  # 48% (FCP)\n",
    "# predictions = algo.test(testset)  # 43% (FCP)\n",
    "# predictions = algo.test(trained_test) # 66%  (FCP)\n",
    "\n",
    "# I find that all the ratings are unity (more or less). That is because the \n",
    "# vast majority of ratings is unity, so the simplest approach is to make everything \n",
    "# unity. \n",
    "\n",
    "# CONCLUSION: I need more variability in the ratings. Or I should have some elements with \n",
    "# zero values. Alternatively, I must add metadata to both the cities and the members. \n",
    "predictions = algo.test(test_not_visited)  # 48% (FCP)\n",
    "\n",
    "\n",
    "\n",
    "# Then compute RMSE\n",
    "sur.accuracy.rmse(predictions)\n",
    "sur.accuracy.fcp(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffc5eb-a9de-4366-bc93-91411a54a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a test set with 10 members and look at all \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bd814-9f7a-4715-820e-78cbaf391114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictions:\n",
    "    if p[0] in users:\n",
    "    # if abs(p[3] < 1.5):\n",
    "        print(p[0], p[2], p[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343edb6e-5bc1-4494-bd30-fb674c7dce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.n_users, y.n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be186891-7228-4e0b-9a73-332932f46762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare number of users in test set against the number in the trainset\n",
    "# I find more users in the test set. However, that means that some users in the test set\n",
    "# are not in the train set. I assume that these uses are simply not considered by Surprise. \n",
    "for t in testset:\n",
    "    users.add(t[0])\n",
    "print(len(users), trainset.n_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2861179-2599-45f6-b376-95bbdaab0d53",
   "metadata": {},
   "source": [
    "## When considering time\n",
    "* The training set is all records from 2016\n",
    "* The testing set is all records from 2017\n",
    "\n",
    "I assumed that a crude temporal estimation would improve the ratings. However, RMSE ratings\n",
    "went from 015 to 0.12 (decrease in accuracy). Note that random guessing is NOT 50% (it is less than 50%) since we are likely dealing with uneven classes and the choice is not binary.\n",
    "Random choice should give 1/80 = 1.2%. So we are much better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19253075-58cf-4936-8845-e2d5989eb985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d033a-97ef-4060-b2ea-f42b088fdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd81f2b-540e-4986-8810-568d24e88de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
